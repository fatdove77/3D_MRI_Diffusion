
""" Taken and adapted from https://github.com/cyclomon/3dbraingen """

import csv
import numpy as np
import torch
from torch.utils.data.dataset import Dataset
import os
from torchvision import transforms
from skimage.transform import resize
from nilearn import surface
import nibabel as nib
import argparse
import glob
import torchio as tio


# class ADNIDataset(Dataset):
#     def __init__(self, root_dir='../ADNI', augmentation=False):
#         self.root_dir = root_dir
#         self.file_names = glob.glob(os.path.join(
#             root_dir, './**/*.nii'), recursive=True)
#         self.augmentation = augmentation

#     def __len__(self):
#         return len(self.file_names)

#     def roi_crop(self, image):
#     # æ£€æŸ¥å›¾åƒç»´åº¦å¹¶é€‚å½“å¤„ç†
#         if image.ndim == 4:
#             # å¦‚æœæ˜¯4Då›¾åƒï¼Œæå–ç¬¬ä¸€ä¸ªé€šé“
#             image = image[:, :, :, 0]
#         elif image.ndim == 3:
#             # å¦‚æœå·²ç»æ˜¯3Då›¾åƒï¼Œä¸éœ€è¦é¢å¤–çš„æ“ä½œ
#             pass
#         else:
#             raise ValueError(f"æ„å¤–çš„å›¾åƒç»´åº¦: {image.ndim}, å½¢çŠ¶: {image.shape}")
        
#         # å‰©ä½™å¤„ç†ä»£ç ä¿æŒä¸å˜
#         mask = image > 0
#         coords = np.argwhere(mask)
#         x0, y0, z0 = coords.min(axis=0)
#         x1, y1, z1 = coords.max(axis=0) + 1   # slices are exclusive at the top
#         cropped = image[x0:x1, y0:y1, z0:z1]
        
#         padded_crop = tio.CropOrPad(np.max(cropped.shape))(cropped.copy()[None])
        
#         # ç¡®ä¿è¿”å›çš„æ˜¯4Dæ ¼å¼ï¼Œä»¥ç¬¦åˆå‡½æ•°çš„é¢„æœŸè¾“å‡º
#         if padded_crop.ndim == 3:
#             padded_crop = padded_crop[..., None]  # æ·»åŠ é€šé“ç»´åº¦
#         else:
#             padded_crop = np.transpose(padded_crop, (1, 2, 3, 0))
        
#         return padded_crop

#     def __getitem__(self, index):
#         path = self.file_names[index]
#         img = nib.load(path)

#         img = np.swapaxes(img.get_data(), 1, 2)
#         img = np.flip(img, 1)
#         img = np.flip(img, 2)
#         img = self.roi_crop(image=img)
#         sp_size = 64
#         img = resize(img, (sp_size, sp_size, sp_size), mode='constant')
#         if self.augmentation:
#             random_n = torch.rand(1)
#             random_i = 0.3*torch.rand(1)[0]+0.7
#             if random_n[0] > 0.5:
#                 img = np.flip(img, 0)

#             img = img*random_i.data.cpu().numpy()

#         imageout = torch.from_numpy(img).float().view(
#             1, sp_size, sp_size, sp_size)
#         imageout = imageout*2-1

#         return {'data': imageout}


#get image and text input 
class CustomDataset(Dataset):
    def __init__(self, root_dir='../ADNI', csv_path=None, augmentation=False):
        self.root_dir = root_dir
        self.augmentation = augmentation
        
        if csv_path is not None:
            # ä»CSVæ–‡ä»¶ä¸­è¯»å–æ•°æ®
            self.samples = []
            with open(csv_path, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    self.samples.append({
                        'image_path': row['image_path'],
                        'description': row['description']
                    })
        else:
            # å¦‚æœæ²¡æœ‰æä¾›CSVï¼Œåˆ™ä½¿ç”¨åŸå§‹æ–¹æ³•æŸ¥æ‰¾æ–‡ä»¶
            self.file_names = glob.glob(os.path.join(
                root_dir, './**/*.nii'), recursive=True)
            self.samples = [{'image_path': path, 'description': ''} for path in self.file_names]

    def __len__(self):
        return len(self.samples)

    def roi_crop(self, image):
        # ä¿æŒä½ åŸæœ‰çš„roi_cropæ–¹æ³•ä¸å˜
        if image.ndim == 4:
            image = image[:, :, :, 0]
        elif image.ndim == 3:
            pass
        else:
            raise ValueError(f"æ„å¤–çš„å›¾åƒç»´åº¦: {image.ndim}, å½¢çŠ¶: {image.shape}")
        
        mask = image > 0
        coords = np.argwhere(mask)
        x0, y0, z0 = coords.min(axis=0)
        x1, y1, z1 = coords.max(axis=0) + 1
        cropped = image[x0:x1, y0:y1, z0:z1]
        
        padded_crop = tio.CropOrPad(np.max(cropped.shape))(cropped.copy()[None])
        
        if padded_crop.ndim == 3:
            padded_crop = padded_crop[..., None]
        else:
            padded_crop = np.transpose(padded_crop, (1, 2, 3, 0))
        
        return padded_crop

    def __getitem__(self, index):
        sample = self.samples[index]
        path = sample['image_path']
        description = sample['description']
        
        # åŠ è½½NIfTIæ–‡ä»¶
        img = nib.load(path)
        img_data = img.get_fdata()  # ä½¿ç”¨get_fdata()æ›¿ä»£å·²å¼ƒç”¨çš„get_data()
        
        # æ£€æŸ¥å›¾åƒå°ºå¯¸
        current_size = img_data.shape[0]  # å‡è®¾å›¾åƒæ˜¯ç«‹æ–¹ä½“(ç›¸åŒå°ºå¯¸)
        
        # å¦‚æœéœ€è¦è°ƒæ•´å°ºå¯¸ä»¥é€‚åº”ç½‘ç»œ(ä»128è°ƒæ•´åˆ°64)
        # å¦‚æœä¸éœ€è¦ï¼Œå¯ä»¥ç§»é™¤è¿™éƒ¨åˆ†
        # sp_size = 128  # æˆ–è€…æ ¹æ®ä½ çš„ç½‘ç»œéœ€æ±‚è®¾ç½®ä¸º128
        # if current_size != sp_size:
        #     img_data = resize(img_data, (sp_size, sp_size, sp_size), mode='constant')
        
        # æ•°æ®å¢å¼º(å¦‚æœéœ€è¦)
        # if self.augmentation:
        #     random_n = torch.rand(1)
        #     random_i = 0.3*torch.rand(1)[0]+0.7
        #     if random_n[0] > 0.5:
        #         img_data = np.flip(img_data, 0)
        #     img_data = img_data*random_i.data.cpu().numpy()
        
        # è½¬æ¢ä¸ºå¼ é‡å¹¶è§„èŒƒåŒ–
        imageout = torch.from_numpy(img_data).float()  ##è¿™é‡Œå¯ä»¥ä¸è§„èŒƒåŒ– é€‰ä¸€ä¸ªåˆ«çš„æ–¹æ³•ï¼Œå› ä¸ºæ•°æ®å·²ç»ä¿®æ”¹å¥½äº†ğŸš§
        
        if len(imageout.shape) == 3:  # å¦‚æœæ˜¯3Då›¾åƒï¼Œæ·»åŠ é€šé“ç»´åº¦
            imageout = imageout.unsqueeze(0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦æ·»åŠ é€šé“
            # imageout = imageout*2-1  # è§„èŒƒåŒ–åˆ°[-1,1]èŒƒå›´    ##å·²ç»è¢«normalizeè¿‡ ğŸš§
        
        return {'data': imageout, 'description': description}
    
    def debug_info(self, num_samples=3):
        # """æ‰“å°æ•°æ®é›†çš„è°ƒè¯•ä¿¡æ¯"""
        print(f"dataset infomation:")
        print(f" numeber of samples : {len(self)}")
        print(f"  root_dir: {self.root_dir}")
        print(f"  augment: {self.augmentation}")
        
        if hasattr(self, 'samples') and self.samples:
            print("\details:")
            for i in range(min(num_samples, len(self))):
                sample_info = self.samples[i]
                data_item = self[i]
                
                print(f"\sample {i}:")
                print(f"  dir: {sample_info['image_path']}")
                print(f"  des: {sample_info['description']}")
                print(f"  shape: {data_item['data'].shape}")
                print(f"  type: {data_item['data'].dtype}")
                print(f"  range: {data_item['data'].min().item()} to {data_item['data'].max().item()}")